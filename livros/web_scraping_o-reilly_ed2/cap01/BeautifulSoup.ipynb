{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04cce343",
   "metadata": {},
   "source": [
    "# Introdução ao BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a2cb80",
   "metadata": {},
   "source": [
    "> Bela Sopa, tão rica e verde, <br>\n",
    "> À espera em uma terrina quente! <br>\n",
    "> Quem não se derreteria por uma iguaria como essa? <br>\n",
    "> Sopa do jantar, bela Sopa! <br>\n",
    "\n",
    "<p style=\"text-align: justify\">\n",
    "A biblioteca BeautifulSoup tem o mesmo nome de um poema de Lewis Carroll que aparece no livro Alice no País das Maravilhas. Na história, esse poema é declamado por uma personagem chamada Falsa Tartaruga (Mock Turtle) – por si só, é um trocadilho com o nome do popular prato vitoriano chamado Sopa Falsa de Tartaruga (Mock Turtle Soup), que não é feito de tartaruga, mas de vaca).\n",
    "</p>\n",
    "<p style=\"text-align: justify\">\n",
    "Assim como o seu homônimo no País das Maravilhas, o BeautifulSoup tenta dar sentido ao que não faz sentido: ajuda a  formatar e a organizar a web confusa, fazendo correções em um código HTML mal formatado e apresentando objetos Python que podem ser facilmente percorridos, os quais representam estruturas XML.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0f0db8",
   "metadata": {},
   "source": [
    "## Instalando o BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a30ef4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dandr\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dandr\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n"
     ]
    }
   ],
   "source": [
    "# Jupyter notebook (já vem com Anaconda)\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba558be",
   "metadata": {},
   "source": [
    "## Executando o BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1f813c",
   "metadata": {},
   "source": [
    "O objeto mais comum usado na biblioteca BeautifulSoup, como não poderia deixar de ser, é o objeto **BeautifulSoup**. Vamos observá-lo em ação, modificando o exemplo apresentado no início deste capítulo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6255d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n",
      "<h1>An Interesting Title</h1>\n",
      "<h1>An Interesting Title</h1>\n",
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('http://www.pythonscraping.com/pages/page1.html') # Armazena o arquivo page1.html\n",
    "bs = BeautifulSoup(html.read(), 'html.parser') # par1:: Texto HTML | par2:: parser escolhido\n",
    "\n",
    "# Imprime a tag h1 definida no HTML (todos tem o mesmo resultado)\n",
    "print(bs.html.body.h1)\n",
    "print(bs.body.h1)\n",
    "print(bs.html.h1)\n",
    "print(bs.h1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae05def",
   "metadata": {},
   "source": [
    "### Outras opções de parser\n",
    "\n",
    "* **lxml:** pip install lxml\n",
    "* **html5lib:** pip install html5lib\n",
    "\n",
    "**obs.:** mais informações na página 25 do livro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0af1c21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "html = urlopen('http://www.pythonscraping.com/pages/page1.html') # Armazena o arquivo page1.html\n",
    "bs = BeautifulSoup(html.read(), 'html5lib') # par1:: Texto HTML | par2:: parser escolhido\n",
    "\n",
    "# Imprime a tag h1 definida no HTML (todos tem o mesmo resultado)\n",
    "print(bs.h1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d65e780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "html = urlopen('http://www.pythonscraping.com/pages/page1.html') # Armazena o arquivo page1.html\n",
    "bs = BeautifulSoup(html.read(), 'lxml') # par1:: Texto HTML | par2:: parser escolhido\n",
    "\n",
    "# Imprime a tag h1 definida no HTML (todos tem o mesmo resultado)\n",
    "print(bs.h1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e3eefd",
   "metadata": {},
   "source": [
    "## Conectando-se de forma confiável e tratando exceções"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fe75b1",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify\">\n",
    "A web é confusa. Os dados são mal formatados, os sites ficam inativos e tags de fechamento podem estar ausentes. Uma das experiências mais\n",
    "frustrantes em web scraping é ir dormir com um scraper executando, sonhar com todos os dados que estarão em seu banco de dados no dia\n",
    "seguinte – somente para descobrir que o scraper deparou com um erro em algum formato de dados inesperado e interrompeu a execução logo depois\n",
    "que você parou de olhar para a tela. Em situações como essas, pode ser tentador amaldiçoar o nome do desenvolvedor que criou o site (e os dados\n",
    "peculiarmente formatados), mas a pessoa que você de fato deveria acusar é a si mesmo, por não ter previsto a exceção, antes de tudo!\n",
    "</p>\n",
    "<p style=\"text-align: justify\">\n",
    "Vamos analisar a primeira linha de nosso scraper, depois das instruções de importação, e descobrir como lidar com qualquer exceção que seja\n",
    "lançada:\n",
    "</p>\n",
    "\n",
    "`html = urlopen('http://www.pythonscraping.com/pages/page1.html')`\n",
    "\n",
    "Dois erros podem ocorrer nessa linha:\n",
    "* A página não é encontrada no servidor (ou houve um erro ao obtê-la).\n",
    "* O servidor não foi encontrado.\n",
    "\n",
    "<p style=\"text-align: justify\">\n",
    "Na primeira situação, um erro de HTTP será devolvido. Esse erro pode ser “404 Page Not Found” (página não encontrada), “500 Internal Server Error” (erro interno do servidor), e assim por diante. Em todos esses casos, a função urlopen lançará a exceção genérica HTTPError. Essa exceção pode ser tratada da seguinte maneira:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fed51796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http.client.HTTPResponse object at 0x000001536D7D32E0>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen \n",
    "from urllib.error import HTTPError\n",
    "\n",
    "try:\n",
    "    html = urlopen('http://www.pythonscraping.com/pages/page1.html')\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "    # devolve null, executa um break ou algum outro \"Plano B\"\n",
    "else:\n",
    "    print(html)\n",
    "    # o programa continua. Nota: se você retornar ou executar um break no\n",
    "    # catch da exceção, não será necessário usar a instrução \"else\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da6d52",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify\">\n",
    "Se um código de erro HTTP for devolvido, o programa agora exibirá o erro e não executará o resto do programa que está na instrução else.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cbf2eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def getTitle(url):\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    try:\n",
    "        bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "        title = bs.body.h1\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    return title\n",
    "    \n",
    "title = getTitle('http://www.pythonscraping.com/pages/page1.html')\n",
    "if title == None:\n",
    "    print('Title could not be found')\n",
    "else:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d23fcdd",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m urlopen\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[1;32m----> 4\u001b[0m html \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://fundamentus.com.br/detalhes.php?papel=PLPL3.html\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Armazena o arquivo page1.html\u001b[39;00m\n\u001b[0;32m      5\u001b[0m bs \u001b[38;5;241m=\u001b[39m BeautifulSoup(html\u001b[38;5;241m.\u001b[39mread(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# par1:: Texto HTML | par2:: parser escolhido\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Imprime a tag h1 definida no HTML (todos tem o mesmo resultado)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('https://fundamentus.com.br/detalhes.php?papel=PLPL3.html') # Armazena o arquivo page1.html\n",
    "bs = BeautifulSoup(html.read(), 'html.parser') # par1:: Texto HTML | par2:: parser escolhido\n",
    "\n",
    "# Imprime a tag h1 definida no HTML (todos tem o mesmo resultado)\n",
    "print(bs) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
